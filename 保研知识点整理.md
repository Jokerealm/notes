# 保研知识点整理

[TOC]



## 一、数学基础

### （一）线性代数

#### 1.求逆矩阵

逆矩阵是矩阵的一个基本操作，它允许我们求解线性方程组，一个$n\times n$的方阵A的逆矩阵记为$A^{-1}$,满足以下条件：
$$
A\cdot{A^{-1}}=A^{-1}\cdot{A}=I
$$
其中，$I$是单位矩阵

求逆矩阵的步骤通常包括：

- 计算矩阵的行列式(determinant),如果行列式为0，则矩阵不可逆
- 计算矩阵的伴随矩阵(adjoint matrix)
- 用伴随矩阵除以行列式得到逆矩阵



#### 2.矩阵的秩

矩阵的秩(rank)是矩阵中线性独立行或列的最大数目，几何上，它表示了矩阵变换后空间的维度

**几何含义**

- 秩为1的矩阵表示将空间压缩到一条线上
- 秩为2的矩阵表示将空间压缩到一个平面上

**应用**

- 在数据降维中，如主成分分析法(PCA),矩阵的秩可以帮助我们确定保留多少主成分



#### 3.线性相关和线性无关

- **线性相关**：如果一组向量可以通过其他向量的线性组合表示，则这些向量是线性相关的
- **线性无关**：如果一组向量中没有任何一个向量可以表示为其他向量的线性组合，则这些向量是线性无关的



#### 4.特征值和特征向量

矩阵的特征值和特征向量是矩阵对某些特殊向量的拉伸或压缩行为的描述。

**定义**：在矩阵$A$的线性变换中，如果存在一个非零向量$v$和一个标量$\lambda$,使得$Av=\lambda v$成立,$\lambda$就是特征值，而$v$就是对应的特征向量

**几何意义**

- **特征向量**是变换下方向不变的向量
- **特征值**是对应特征向量拉伸或压缩的倍数

**应用**

- 在机器学习中，特征值和特征向量被用于计算对象的特征，如在特征向量分析中



#### 5.矩阵的等价、合同、相似

- **等价**：如果两个矩阵可以互相通过行和列的交换得到，则他们是等价的
- **合同**：如果存在一个可逆矩阵$C$，使得$A=C^TBC$，则$A$和$B$是合同的
- **相似**：如果存在一个可逆矩阵$P$,使的$A=P^{-1}BP$,则$A$和$B$是相似的

**三者的关系**

- 相似矩阵有相同的特征多项式和相同的特征值
- 合同矩阵有相同的秩
- 等价矩阵有相同的行列式和迹



#### 6.向量的基

- **基**：在向量空间中，一组基是一组线性无关的量，可以通过它们的线性组合来表示空间中的任何向量。
- **性质**：基不是唯一的，任何向量空间都有无穷多个基。基向量的选择可以影响向量的坐标表示，但不会改变向量本身



#### 7.几何重数

一个特征值的几何重数是指解特征方程$(A-\lambda I)v=0$时，线性无关的特征向量的个数。几何重数表示了特征空间的维度，即特征值对应的特征向量集合的维数



#### 8.代数重数

一个特征值的代数重数是指在特征多项式$\det(A-\lambda I)$中，该特征值作为根的重复次数。代数重数反映了特征值在特征多项式中的重复性，它与特征向量的求解和矩阵的对角化过程密切相关。

### （二）高等数学

#### 1.连续、可导、可微

**连续**：如果$\lim_{x\rightarrow{a}}f(x)=f(a)$，则函数$f(x)$在某一点$a$处连续

**可导**：如果函数$f(x)$在某一点$a$可导，则存在极限$\lim_{h\to{0}}\frac{f(a+h)-f(a)}{h}$

**可微**：如果函数$f(x)$在某一点$a$处可微，则存在实数$A$,使得$\lim_{h\to{0}}\frac{f(a+h)-f(a)-A\cdot{h}}{h}=0$



#### 2.连续与一致连续

**连续**：如果对于任意的$\epsilon>0$,存在$\delta>0$,使得当$0<|x-a|<\delta$时，有$|f(x)-f(a)|<\epsilon$，则函数$f(x)$在某一点$a$连续

**一致连续**：如果对于任意的$\epsilon>0$,存在$\delta>0$,使得对于区间$I$上任意两点$x$和$y$,当$|x-y|<\delta$时，有$|f(x)-f(y)|<\epsilon$,则函数$f(x)$在区间$I$上一致连续



#### 3.一阶导数与二阶导数

**几何含义**

- 一阶导数$f(x)$表示函数在某点的瞬时变化率，即切线的斜率。
- 二阶导数$f''(x)$表示一阶导数的变化率



#### 4.函数的凹凸性（从y轴看凹凸性）

函数的凹凸性可以通过二阶导数判断：

- 如果$f''(x)>0$,则函数在该区间为凸函数
- 如果$f''(x)<0$,则函数在该区间为凹函数



#### 5.梯度和散度

**梯度**：梯度是一个**向量**，表示函数增长最快的方向，数学表达式为$\nabla f=(\frac{\partial f }{\partial x_1},\frac{\partial f }{\partial x_2},...,\frac{\partial f }{\partial x_n})$

**散度**：散度是一个**标量**，用于描述向量场的发散性，数学表达式为$\operatorname{div} F=\sum\limits^{n}_{i=1}\frac{\partial F_i }{\partial x_i}$,其中，$\operatorname{F}=(F_1,F_2,...,F_n)$是向量场

**应用**

- **梯度**在优化问题中用于寻找函数的局部最小值，如机器学习中的梯度下降法
- **散度**在物理学中描述了场的发散性，如电场或磁场的发散性



#### 6.函数的零点和极值点的求法

- **零点**：函数的零点是使得函数值为零的自变量的值，即解方程$f(x)=0$。求函数零点的基本方法是将函数设为零，然后解得到的方程
- **极值点**：函数的极值点是函数局部的最大值或最小值。求极值点通常涉及求导数，首先求函数的一阶导函数$f'(x)$,然后找到导函数为0或不存在的点，这些点可能是极值点，然后通过二阶导数测试等方法来确定这些点是极大值点还是极小值点



#### 7.解析和奇点

- **解析**：在复分析中，一个复函数在某点是解析的，如果它在该点的任意小的领域内可以由泰勒级数表示。解析函数在复平面上通常没有奇点，并且满足柯西-黎曼方程
- **奇点**：奇点是函数不解析的点，也就是说，在奇点附近，函数不能由泰勒级数展开。奇点可以是孤立的，也可以是本质的。孤立奇点可以通过局部分析来研究，而本质奇点则表明函数在该点附近的行为完全不同



#### 8.间断点

- **第一类间断点**：也称为可去间断点或跳跃间断点。如果函数在某点的左极限和右极限都存在，但不等于该点的函数值，或者函数在该点没有定义，那么这个点是第一类间断点
- **第二类间断点**：如果函数在某点的左极限和右极限至少有一个不存在，或者存在但与函数值的差是无限大，那么这个点是第二类间断点。第二类间断点包括无穷间断点和振荡间断点



#### 9.零点存在定理、介值定理

- **零点存在定理**：如果一个连续函数$f(x)$在区间$[a,b]$上的两个端点处的函数值异号，即$f(a)\cdot f(b)<0$,那么至少存在一个$c\in(a,b)$使得$f(c)=0$.这个定理保证了在区间内至少有一个零点
- **介值定理**：对于一个在闭区间$[a,b]$上连续的函数$f(x)$，如果$f(a)$和$f(b)$之间存在一个值$L$，那么至少存在一个$c\in [a,b]$，使得$f(c)=L$。介值定理说明了连续函数可以取到它在区间端点连线上任何一点的函数值



#### 10.黎曼积分、黎曼和的定义

- **黎曼积分**：用于描述一个函数在某个区间上积分的精确值。如果一个函数$f$在区间$[a,b]$上是黎曼可积的，那么存在唯一一个实数$I$，使得对于任意的正数$\epsilon>0$,都存在一个正数$\delta>0$,使得满足$\frac{1}{\delta}<N$的黎曼和$S_N$与$I$的差的绝对值小于$\epsilon$
- **黎曼和**：黎曼和是将积分区间分割为多个小区间，然后在每个小区间上取一个代表性的点（通常是区间的端点或中点），将这些点处的函数值与区间长度相乘后求和得到的。黎曼和的极限（当分割的区间数量趋于无穷大时）就是黎曼积分的值



#### 11.积分中值定理

如果函数$f(x)$在区间$[a,b]$上连续，那么存在一个$c\in[a,b]$使得$\int^{a}_{b}f(x)dx=f(c)(b-a)$​。这个定理说明了在积分过程中，函数在某点的值与整个区间的积分值有一个线性的关系。它与微分中的罗尔定理相似，但适用于积分而不是导数



#### 12.泰勒展开

**定义**：泰勒展开是一种将一个函数表示为无限多个多项式的和的方法，这些多项式由函数在某一点的导数决定，泰勒展开可以用于近似计算某些函数的值。

**应用**：在计算机领域中，泰勒展开是数值分析的理论基础之一，在图像处理、数字信号处理、物理模拟等领域中广泛应用。例如，在图像处理中，泰勒展开可以用来近似计算图像中某个区域的像素值。



#### 13.==傅立叶变换==

**定义**：傅立叶变换是一种将一个函数表示为无限多个正弦和余弦函数的和的方法。它可以将一个信号分解成不同频率的分量，并将这些分量可视化。

**应用**：傅立叶变换在信号处理、图像处理、音频处理等领域中广泛应用。例如，在音频处理中，傅立叶变换可以将声音信号分解成不同频率的声音成分，并可以对这些成分进行滤波、增强等操作。

在计算机领域中，泰勒展开和傅立叶变换常常一起使用。例如，在图像压缩中，可以先使用泰勒展开将图像表示为一组多项式的和，然后再使用傅立叶变换将每个多项式表示为正弦和余弦函数的和，从而实现图像的压缩。此外，在机器学习领域中，傅立叶变换可以用于特征提取，而泰勒展开可以用于优化算法中的目标函数近似。



### （三）概率论

#### 1.全概率公式和贝叶斯公式

**全概率公式**

设事件$A_1,A_2,...,A_n$构成一个完备事件群（即他们互斥且他们的并集为整个样本空间），且每个$A_i$都有正概率，则任意事件$B$的概率可以表示为：
$$
P(B)=P(A_1)P(B|A_1)+P(A_2)P(B|A_2)+...+P(A_n)P(B|A_n)
$$
**贝叶斯公式**

贝叶斯公式用于求解在某些条件下，求一个事件的概率，其表达式为
$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$
其中，$P(A|B)$是条件概率，表示在事件$B$发生的条件下，事件$A$发生的概率



#### 2.大数定理

大数定理表明，随着独立同分布的随机变量序列的样本量$n$趋于无穷，它们的样本均值趋于总体均值
$$
\overline{X}=\frac{1}{n}\sum\limits^{n}_{i=1}X_i
$$
同时，当$n\to\infty$,有$\overline{X}\to{\mu}$



#### 3.伯努利大数定理

伯努利大数定理是大数定理在伯努利试验下的特例，他指出，对于独立同分布的伯努利试验，随着试验次数$n$的增加，成功的概率（即事件$A$发生的概率$P(A)$）将趋于其期望值
$$
P=\lim_{n\to\infty}\frac{1}{n}\sum\limits^{n}_{i=1}X_i
$$
其中，$X_i$是第$i$次试验的结果，取值为1或0（成功为1，失败为0）



#### 4.中心极限定理

中心极限定理指出，对于独立同分布的随机变量$X_1,X_2,...,X_n$,它们的和$S_n=\sum^{n}_{i=1}X_i$,在$n$足够大的情况下，无论$X_i$的分布如何，标准化后的和$\frac{S_n-n\mu}{\sigma\sqrt{n}}$将趋于正态分布：
$$
\lim_{x\to\infty}P(\frac{S_n-n\mu}{\sigma\sqrt{n}}\le z)=\Phi(z)
$$
其中，$\Phi(z)$是标准正态分布的累积分布函数



#### 5.点估计、区间估计和矩估计

**点估计**

点估计是用样本数据来估计总体参数的值，例如，总体均值的点估计为样本均值：
$$
\widehat{\mu}=\widehat{x}=\frac{1}{n}\sum\limits^{n}_{i=1}x_i
$$
**区间估计**

区间估计是在点估计的基础上，给出一个区间，该区间以一定的概率包含总体参数，例如，总体均值的95%置信区间可以表示为：
$$
\overline{x}\pm z_{\alpha/2}\frac{s}{\sqrt{n}}
$$
其中，$z_{\alpha/2}$是标准正态分布的$\alpha/2$分位数,$s$是样本标准差

**矩估计**

矩估计是基于样本矩来估计总体矩，进而估计总体参数的方法。例如，总体方差的矩估计（即样本方差）为：
$$
s^2=\frac{1}{n-1}\sum\limits^{n}_{i=1}(x_i-\widehat x)^2
$$



#### 6.无偏性、有效性、相合性（一致性）

- **无偏性**：在统计学中，一个估计量被称为是无偏的，如果它的期望值等于被估计的参数的真实值。换句话说，无偏估计量在多次重复抽样情况下，其平均值将接近所估计的参数
- **有效性**：有效性是指在所有无偏估计量中，具有最小方差的估计量的性质。有效估计量提供了对参数的最佳9即最精确）无偏估计
- **一致性**：一个序列的估计量被称为是一致的，如果随着样本大小的增加，这些估计量收敛到被估计的参数的真实值。一致性强调了估计量随着样本量的增加而趋于稳定的特性



#### 7.切比雪夫大数定律

对于独立同分布的随机变量序列，它们的样本均值随着样本量的增加而趋于总体均值。更具体地，她提供了一个不等式来量化样本均值偏离总体均值的概率。
$$
P(|\overline{X}-\mu|\ge k\sigma/n)\le \frac{1}{k^2}
$$
其中，$\overline{X}$是样本均值，$\mu$是总体均值，$\sigma$是总体标准差，$n$是样本大小，$k$是任意正实数



#### 8.正态分布

正态分布也称高斯分布，是一种连续概率分布。正态分布的概率密度函数具有两个参数，均值$\mu$和方差$\sigma^2$,其概率密度分布函数(PDF)为：
$$
f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$


#### 9.泊松分布

泊松分布是一种描述在固定时间或空间内发生稀有事件次数的概率分布，它是一种离散分布，常用于计数数据。泊松分布的概率质量函数为
$$
P(X=k)=\frac{e^{-\lambda}\lambda^k}{k!}
$$
其中，$\lambda$是单位时间或单位面积内事件发生的平均次数，$k$是可能的事件总数



#### 10.指数分布

指数分布是一种描述两个连续事件之间时间间隔的连续概率分布。他是一种单参数分布，通常用于描述独立随机事件发生的时间间隔。指数分布的概率密度函数为
$$
f(x)=\lambda e^{-\lambda x}
$$
其中，$\lambda$是单位时间内事件平均发生率，$x$是时间间隔。指数分布具有无记忆性，即如果一个随机事件服从指数分布，那么无论已经等待了多长时间，未来某个时间段内事件发生的概率不依赖于已经等待的时间



#### 11.概率密度函数

**定义**：概率密度函数PDF是==连续型随机变量==的分布函数，用$f(x)$表示。对于任意区间$(a,b)$，随机变量$X$落在这个区间的概率是$P(a<X\le b)=\int^b_a f(x)dx$

**性质**：

1. 非负性：$f(x)$对于所有$x$值都是非负的
2. 归一性：整个概率空间的积分为1，即$\int^{+\infty}_{-\infty}f(x)dx=1$
3. 可加性：随机变量落在某个区间的概率等于该区间上概率密度函数的积分



#### 12.联合概率

**定义**：联合概率是指两个或多个随机变量共同发生的概率。对于两个随机变量$X$和$Y$，它们的联合概率密度函数用$f_{X,Y}(x,y)$表示

**特点**：

- 描述了两个随机变量之间的依赖关系
- 如果$X$和$Y$是独立的，那么$f_{X,Y}=f_X(x)f_Y(y)$,其中$f_X(x)$和$f_Y(y)$分别是$X$和$Y$的边缘概率密度函数



#### 13.边缘概率

**定义**：边缘概率是指在多变量情况下，只关注其中一个随机变量的概率分布，而忽略其他变量。对于联合概率密度函数$f_X(x)=\int^{+\infty}_{-\infty}f_{X,Y}(x,y)dy$

**特点**：

- 边缘概率密度函数提供了关于==单个==随机变量的概率信息，而不考虑其他变量
- 边缘概率可以用来计算单个随机变量落在某个区间的概率，就像处理单一随机变量一样



#### 14.马尔可夫过程

**定义**：马尔可夫过程是一种随机过程，其未来状态只依赖于当前状态，而与过去的状态无关，这种性质称为马尔科夫性质或无记忆性

**特点**：每个状态在下一时间点转移到另一个状态的概率只依赖于当前状态



#### 15.假设检验

**定义**：假设检验是数理统计中的一种方法，用于基于样本数据来判断一个关于总体的假设是否成立

**过程**：

- 提出**零假设**（$H_0$）:通常表示没有效益或差异的假设
- 提出**备择假设**（$H_1$）：与零假设相对，表示有效应或差异的假设
- 选择显著性水平（$\alpha$）：通常为0.05或0.01，表示犯第一类错误(错误地拒绝零假设)的概率上限
- 计算检验统计量和p值：p值表示在零假设为真的情况下，观察到当前或更极端样本结果的概率
- 做出决策：如果p值小于显著性水平，则拒绝零假设，接受备择假设



#### 16.数学期望和方差

**期望**：是随机变量的平均值，表示如果实验重复无限次，随机变量取值的平均结果。
$$
E(X)=\sum^{n}_{i=1}x_iP(X=x_i), 离散化随机变量\\
E(X)=\int_{-\infty}^{+\infty}xf(x)dx,连续随机变量
$$
**方差**：衡量随机变量偏离其期望值的程度，即方差越大，数据的分散程度越高。
$$
Var(X)=E((X-E(X))^2)
$$


## 二、专业课

### （一）操作系统

#### 1.进程与线程

**进程与线程的区别**：

- 线程是进程中的一个实体，是CPU调度和执行的单位，同一进程的线程共享进程的资源
- 进程是资源分配的基本单位，拥有独立的内存空间和系统资源

**死锁**：

死锁是指两个或多个进程在执行过程中，因争夺资源而造成的一种僵局

**避免死锁的方法**：

- 预防策略：银行家算法
- 避免策略：如资源分配图
- 检测与恢复：如死锁检测算法和资源回收



#### 2.调度算法

**常见的CPU调度算法**：

- 先来先服务（FCFS）
- 短作业优先（SJF）
- 轮转（RR）
- 优先级调度

**优缺点比较**：

- **FCFS**：简单，但不利于长作业
- **SJF**：响应时间短，但可能导致饥饿现象
- **RR**：适合时间共享系统，但不利于长作业
- **优先级调度**：响应速度快，可能导致饥饿



#### 3.内存管理

**分页与分段的区别**：

- **分页**是物理内存分割成固定大小的块，每个块称为页框
- **分段**是将程序按照功能划分为多个段，每个段可以动态增长和缩减

**内存管理技术**：

- **虚拟内存**：使用硬盘空间作为内存的扩展
- **页表**：记录虚拟地址和物理地址的映射关系
- **TLB**（快表）：用于加速页表的访问



#### 4.并发与同步

**信号量和互斥量**：

- 信号量用于控制对共享资源的访问，允许多个进程同时访问资源
- 互斥量用于确保在同一时间只有一个进程可以访问共享资源

**进程同步**：

- 使用信号量和互斥量来控制对共享资源的访问，避免数据不一致和竞态条件
- 信号量常用于生产者-消费者问题，互斥量用于临界区的保护



#### 5.中断和系统调用的区别

中断（Interrupt）和系统调用（System Call）是操作系统中常用的两种机制，它们有着
不同的应用场景和工作方式。
中断是指外部事件（如I/O 设备的数据传输完成、时钟中断等）打断了CPU 当前正在执行的程序，转而执行中断服务程序。中断服务程序是操作系统为处理中断事件而预先定义好的程序，用于对中断事件进行处理，然后返回中断发生之前的程序继续执行。中断可以分为硬件中断和软件中断，其中硬件中断是由CPU 或I/O 设备发出的，而软件中断是由当前执行的程序中的指令发出的。系统调用是软中断的一种。
总的来说，中断是由外部事件触发的，用于实时响应事件并进行处理，而系统调用是由
应用程序发起的，用于访问操作系统提供的资源和服务。



#### 6.进程间的通信方式

- **管道**：可以在两个进程之间创建一个单向管道，数据从一个进程流向另一个进程。
- **消息队列**：可以在两个进程之间创建一个消息队列，一个进程往消息队列里写数据，另一个进程从消息队列中读取数据。
- **共享内存**：可以在两个进程之间共享一块内存区域，不同的进程可以通过对内存区域的读写来实现数据共享。
- **信号量**：可以用来控制进程之间对共享资源的访问，多个进程可以通过对信号量的加锁和解锁来协调对共享资源的访问。



#### 7.死锁

**定义**：死锁是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。

**死锁产生的四个必要条件**：

互斥条件：在一段时间内某资源只由一个进程占用。

请求与保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其他资源保持不放。

不剥夺条件：进程已获得的资源，在未使用完之前，不能被强行剥夺，只能在使用完时自己释放。

循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系。

**如何预防死锁**：

破坏互斥条件：有些资源可以同时被多个进程使用，如打印机等。

破坏请求与保持条件：一次性申请所有需要的资源，或在申请资源时，一次性申请所有的资源。

破坏不剥夺条件：允许抢占，当一个进程请求新的资源而得不到满足时，该进程可以释放自己持有的资源，并且重新开始申请资源。

破坏循环等待条件：对资源进行编号，进程只能按照编号递增的顺序来请求资源。



#### 8.哲学家进餐

哲学家进餐问题是指若干个哲学家围坐在一张圆桌旁，每个哲学家的左右两边分别放有一只筷子，哲学家必须同时拿到左右两只筷子才能进餐，否则就需要等待。这个问题的关键是如何保证哲学家能够正确地获取筷子，而不会陷入死锁状态。
以下是几种解决方案：
资源分级法：给筷子赋予编号，规定哲学家只能先拿左边编号较小的筷子，再拿右边编号较大的筷子。这样可以避免哲学家同时拿起自己左边的筷子而造成死锁。
Chandy/Misra 解法：每个哲学家拿筷子的时候，先向其他哲学家请求，如果请求不到，则等待一段时间后重试，如果还是请求不到，就释放已经拿到的筷子。这样可以防止死锁的产生。
Dijkstra 解法：给每个哲学家规定一个状态，分别是思考、饥饿、就餐三种状态。对于任意两个相邻的哲学家，如果左边哲学家正在就餐，右边哲学家就必须等待，如果左边哲学家已经离开，右边哲学家可以先抢到左边的筷子。这种方式可以避免死锁。



#### 9.银行家算法

**定义**：银行家算法是一种避免死锁的算法，它是一个基于资源分配的算法，用于确保系统中的进程不会因为资源不足而陷入死锁状态。银行家算法的基本思想是模拟银行家的行为，即系统管理者需要对系统中的资源进行合理的分配。
**过程**：当一个进程提出资源请求时，银行家算法会检查是否有足够的资源可以分配给该进程，如果有，则分配给该进程；否则该进程必须等待。在分配资源之前，银行家算法会对系统的状态进行检查，以确保分配资源后系统不会陷入死锁状态。如果分配资源后系统仍然是安全的，银行家算法会执行分配操作，并修改相应的向量和矩阵。




#### 10.分页和分段

**定义**：在操作系统中，分页和分段都是内存管理中的两种技术。它们的作用是将进程的虚拟地址空间映射到物理内存中，使得进程能够访问其所需的内存。

**区别**：

1. 页是信息的物理单位，分页是为了实现非连续分配，以便解决内存碎片问题，或者说分页是由于系统管理的需要。段是信息的逻辑单位，分段的目的是为了更好地实现共享，满足用户的需要。
2. 页的大小固定且由系统确定，而段的长度却不固定，决定于用户所编写的程序。
3. 分页的作业地址空间是一维的；分段的地址空间是二维的。

#### 11.虚拟内存和共享内存

- 虚拟内存是一种操作系统的内存管理技术，它允许应用程序访问比物理内存更大的内存空间。当物理内存不足时，操作系统会将一部分内存空间临时存储到硬盘上，以释放物理内存供其他程序使用。在应用程序访问这些被临时存储的内存空间时，操作系统会自动将其调回物理内存，这个过程对应的就是页面置换。
- 共享内存则是一种进程间通信的机制，可以让不同进程之间共享同一块物理内存区域。这种内存区域可以被多个进程同时访问，因此能够提高程序的运行效率和并发性。共享内存可以通过操作系统提供的API 来创建和管理，通常需要加锁机制来确保进程间访问的安全性。

#### 12.页面置换算法

**定义**：页面置换算法是指当内存不足时，选择将哪些页面换出到磁盘上，腾出内存空间给新的页面使用的算法。

常见的页面置换算法有：

- **最优页面置换算法（OPT）**：理论最佳算法，选择离下一次使用时间最长的页面进行置换。但是这种算法无法实现，因为无法预测页面下一次使用时间。
- **先进先出页面置换算法（FIFO）**：选择最早进入内存的页面进行置换。
- **最近最少使用页面置换算法（LRU）**：选择最近最久未使用的页面进行置换。
- **时钟页面置换算法**：基于FIFO 算法，通过维护一个页面链表和一个时钟指针，当时钟指针指向的页面被访问时，将该页面的访问位设为1，下次遍历页面链表时，只将访问位为0 的页面进行置换。
- **最近未使用页面置换算法（NRU）**：通过维护页面访问位和修改位，根据访问位和修改位的组合进行页面置换。



#### 13.缓冲区溢出

**定义**：缓冲区溢出是指在向缓冲区写入数据时，超出了缓冲区的可用空间，导致溢出到相邻内存区域或者覆盖其他重要的数据。缓冲区溢出会引起严重的安全问题，比如攻击者可以利用缓冲区溢出来修改程序的执行流，从而实现代码注入、执行任意代码等攻击行为。
**方法**：

1. 限制缓冲区大小：当程序试图往缓冲区写入数据时，操作系统会检查是否超过了缓冲区的大小，如果超过了则不允许写入。使用编程语言提供的安全函数这些函数可以在写入数据时检查缓冲区是否越界，从而避免缓冲区溢出。
2. 使用堆栈保护器：编译器可以在程序运行时检查函数的返回地址是否被修改，从而避免缓冲区溢出攻击。
3. 代码审计：通过对程序源代码的审查，可以发现潜在的缓冲区溢出漏洞，并进行修复。



### （二）数据结构

#### 1.线性数据结构

- **数组**：使用连续的内存空间存储具有相同类型的元素
- **链表**：由一系列节点组成，每个节点包含数据部分和指向下一个节点的指针
- **栈**：遵循后进先出（LIFO）原则的线性数据结构
- **队列**：遵循先进先出（FIFO）原则的线性数据结构



#### 2.树形数据结构

- **二叉树**：每个节点最多有两个子节点的树结构
- **平衡树**：自动保持平衡的二叉树，如AVL树，以维持高效的查找时间
- **堆**：特殊类型的树，满足堆性质，常用于实现优先队列



#### 3.图形数据结构

- **图**：由顶点（节点）和边组成，可以是加权或无权的
- **最小生成树**：连接图的所有顶点的树，边的权重之和最小的问题
- **最短路径算法**：如Dijkstra算法，用于在图中找到两点间的最短路径



#### 4.散列（哈希）

- **哈希表**：使用哈希函数将键映射到表中的一个索引，以支持快速数据访问
- **冲突解决**：处理哈希表中键映射到同一索引的情况，如链地址法和开放寻址法



#### 5.算法效率

- **时间复杂度**：算法执行所需时间与输入规模的关系
- **空间复杂度**：算法执行过程中所需的存储空间量



#### 6.排序算法

- **冒泡排序**：通过重复遍历待排序序列，比较并交换相邻元素实现排序
- **快速排序**：采用分治法策略，通过一个基准值将序列分为两部分排序
- **归并排序**：将序列分为多个小序列，排序后再合并为有序序列



#### 7.查找算法

- **线性查找**：从列表的第一个元素开始，逐个查找目标元素
- **二分查找**：在有序数组中查找元素，每次比较中间元素，缩小查找范围



#### 8.高级数据结构

- **并查集的优化和应用**：并查集可以通过联合路径压缩和按秩合并来优化，减少查找操作的复杂度，在网络连通性问题、社交网络分析、集合操作等场景中有广泛应用

- **布隆过滤器的改进和应用**：布隆过滤器可以结合不同的哈希函数来减少误判率，也可以通过动态调整大小来适应不同的数据集，在大数据流处理、缓存击中判断、去重等场景中有实际应用



#### 10.排序

**插入排序（Insertion Sort）**：

基本思想：将一个待排序的数组分为已排序区间和未排序区间，每次取出未排序区间中的第一个元素，插入到已排序区间的合适位置中。

时间复杂度：最好情况下，已经是有序的，时间复杂度为O(n)；最坏情况下，数组是倒序排列的，时间复杂度为$O(n^2)$；平均时间复杂度为$O(n^2)$。

稳定性：稳定排序算法。

**希尔排序（Shell Sort）**：

基本思想：是对插入排序的一种改进。将待排序数组按照一定的间隔分组，对每组进行插入排序。随着间隔的逐渐缩小，每组包含的元素越来越少，最后间隔为1，即对整个数组进行插入排序。

时间复杂度：最好情况下，时间复杂度为$O(nlogn)$；最坏情况下，时间复杂度为$O(n^2)$；

平均时间复杂度为$O(n^{1.3})$。

稳定性：不稳定排序算法。

**选择排序（Selection Sort）**：

基本思想：将一个待排序的数组分为已排序区间和未排序区间，每次从未排序区间中选择最小的元素，放入已排序区间的末尾。

时间复杂度：无论最好、最坏或平均情况下，时间复杂度都为$O(n^2)$。

稳定性：不稳定排序算法。

**冒泡排序（Bubble Sort）**：

基本思想：将一个待排序的数组分为已排序区间和未排序区间，每次比较相邻的两个元素，如果它们的顺序不正确，则交换它们的位置。

时间复杂度：无论最好、最坏或平均情况下，时间复杂度都为$O(n^2)$。

稳定性：稳定排序算法。

**归并排序（Merge Sort）**：

基本思想：采用分治的思想，将待排序数组分成左右两部分，分别对左右两部分进行递归排序，最后将排好序的左右两部分合并起来。

时间复杂度：无论最好、最坏或平均情况下，时间复杂度都为$O(nlogn)$。

稳定性：稳定排序算法。

**快速排序**：

快速排序的基本思想是分治思想，通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，然后再按此方法对这两部分记录分别进行快速排序，以达到整个序列有序的目的。具体实现可以采用递归或迭代方式实现。时间复杂度为$O(nlogn)$，但最坏情况下时间复杂度为$O(n^2)$。快速排序不是稳定排序，因为在排序过程中会改变相同元素之间的相对位置。

**堆排序**：

堆排序的基本思想是将待排序序列构造成一个大顶堆或小顶堆，然后将堆顶元素与堆底元素交换，再将剩余元素重新调整为大顶堆或小顶堆，重复进行交换和调整操作，直到整个序列有序。时间复杂度为$O(nlogn)$，是一种稳定排序算法。

**基数排序**：

基数排序的基本思想是将待排序序列按照某一位数进行排序，然后再按照下一位数进行排序，直到所有位数都排完为止。具体实现可以采用桶排序的思想，将待排序元素按照当前位数的值放入对应的桶中，然后按照桶的顺序依次将元素取出，重复以上操作直到排序完成。

时间复杂度为$O(d(n+r))$，其中d 为最大位数，r 为基数（通常为10），是一种稳定排序算法。

**冒泡排序**：

冒泡排序的最坏情况是待排序序列已经是倒序排列的情况，需要进行$n-1 $轮比较，每轮需要比较$n-i$ 次，即比较次数为：$(n-1) + (n-2) + ... + 1 = n(n-1)/2$，因此在最坏情况下，冒泡排序需要进行约$n^2/2 $次比较。

**快速排序**：

快速排序的最坏情况是待排序序列已经是有序或近似有序的情况，此时每次划分只能将待排序序列分成一个元素和$n-1 $个元素，需要进行$n-1 $次划分，每次划分需要比较$n-i$ 次，即比较次数为：$(n-1) + (n-2) + ... + 1 = n(n-1)/2$，因此在最坏情况下，快速排序需要进行约$n^2/2$

次比较。因此，在最坏情况下，冒泡排序和快速排序的比较次数都为约$n^2/2$ 次。但是在平均情况下，快速排序的比较次数要比冒泡排序少很多，因此快速排序的平均时间复杂度为$O(nlogn)$，而冒泡排序的平均时间复杂度为$O(n^2)$​。



#### 11.最小生成树和最短路径

**图的最小生成树**（Minimum Spanning Tree，简称MST）是指在一个连接所有节点的无向加权图中，找到一棵生成树，使得树上所有边的权重之和最小。
**普利姆算法（贪心算法）：**
1.将连通网中的所有顶点分为两类（假设为A 类和B 类）。初始状态下，所有顶点位于B类；
2.选择任意一个顶点，将其从B 类移动到A 类；
3.从B 类的所有顶点出发，找出一条连接着A 类中的某个顶点且权值最小的边，将此边连接着的A 类中的顶点移动到B 类；
4.重复执行第3 步，直至B 类中的所有顶点全部移动到A 类，恰好可以找到N-1 条时间复杂度为O(ElogV)或O(V^2)，其中E 为边数，V 为顶点数。可以通过使用堆等数据结构来优化算法。
**迪杰斯特拉算法**：
迪杰斯特拉算法的基本思想是维护一个到源点已经确定了最短路径的顶点集合S，然后从剩余的顶点中选择一个到源点距离最短的顶点加入到集合S 中，并更新其它顶点到源点的距离值。重复以上步骤，直到所有顶点都加入到集合S 中为止。

时间复杂度为O(V^2)或O(ElogV)，其中E 为边数，V 为顶点数。可以通过使用优先队列等数据结构来优化算法。
在优化迪杰斯特拉算法时，可以使用堆等数据结构来维护未确定最短路径的顶点集合，从而将时间复杂度降至O(ElogV)。另外，可以使用动态规划等算法来解决最短路径问题，时间复杂度为==O(V^3)或O(EV)==。
**弗洛依德算法**：
弗洛依德算法是一种动态规划算法，用于求解所有顶点之间的最短路径。它的基本思想是维护一个二维数组dist，其中dist[i][j]表示从顶点i 到顶点j 的最短路径长度。算法的核心是一个三重循环，每次通过比较经过中间顶点k 的路径和直接路径的长度，更新dist[i][j]的
值。时间复杂度为==O(V^3)==，其中V 为顶点数。可以通过使用空间换时间的方法，在计算过程中记录中间顶点，从而避免重复计算。
**克鲁斯卡尔算法**：
克鲁斯卡尔算法是一种贪心算法，用于求解带权无向图的最小生成树。它的基本思想是按照边的权值升序排列，依次将边加入生成树中，但是需要保证生成树不形成环。算法的核心是使用并查集来维护已经加入到生成树中的顶点，以及它们所在的连通分量。时间复杂度
为==O(ElogE)==，其中E 为边数。可以通过使用堆等数据结构来优化算法。
在优化克鲁斯卡尔算法时，可以使用并查集等数据结构来维护已经加入到生成树中的顶点，以及它们所在的连通分量。另外，在处理边的权值时，可以使用快速排序等算法来加速排序的过程，从而提高算法的效率。



#### 12.哈夫曼编码

哈夫曼编码（Huffman Coding）是一种常用的数据压缩算法，通过根据字符出现的频率分配不同长度的编码，实现对数据的高效压缩。
**原理**：

1. 统计字符频率：对待压缩的数据进行扫描，统计每个字符出现的频率。
2. 构建哈夫曼树：根据字符频率构建哈夫曼树。频率越高的字符距离根节点越近。
3. 分配编码：从根节点开始，沿着哈夫曼树的路径分配编码，给左子树分配0，给右子树分配1。最终，每个字符都有一个唯一的二进制编码。
4. 生成编码表：根据分配的编码，生成一个编码表，将字符与对应的编码进行映射。
5. 进行编码：使用生成的编码表，将原始数据中的每个字符替换为对应的编码。
6. 进行解码：使用相同的哈夫曼树和编码表，将编码后的数据解码为原始数据。

**优势**：

1. 变长编码：哈夫曼编码采用变长编码，使得出现频率高的字符可以使用较短的编码，而出现频率低的字符可以使用较长的编码，从而实现对数据的高效压缩。
2. 唯一解码性：由于哈夫曼编码是无前缀编码（即没有一个编码是另一个编码的前缀），因此解码过程中不会出现歧义，可以唯一还原原始数据。
3. 无损压缩：哈夫曼编码是一种无损压缩算法，即解压缩后能够完全还原原始数据，不会损失任何信息。



哈夫曼编码在诸如文件压缩、图像压缩、音频压缩等领域都有广泛的应用。



#### 13.图的拓扑排序(Tpological Sorting)

图的拓扑排序（Topological Sorting）是对有向无环图（DAG）进行排序的一种算法。它通过将图中的节点按照一定的顺序排列，使得所有的有向边从排在前面的节点指向排在后面的节点。换句话说，拓扑排序将图中的节点线性化，使得所有的依赖关系都得到满足。
**概念**：

1. 对于有向无环图（DAG）而言，拓扑排序给出了一种节点的线性排序方式，使得对于任意一条有向边(u, v)，在排序中节点u 都排在节点v 的前面。
2. 拓扑排序并不唯一，一个图可以有多个合法的拓扑排序序列。

**应用**：拓扑排序是一种对有向无环图进行排序的算法，通过确定节点的线性顺序，使得所有的依赖关系都得到满足。它在任务调度、编译顺序、课程安排等场景中有广泛的应用。



#### 14.并查集

**定义**：并查集（Disjoint Set），也称为不相交集合或合并-查找集合，是一种用于处理集合合并和查找连通分量的数据结构。它提供了一种高效的方式来解决连通性问题。

**性质**：

1. 并查集维护了一组互不相交的集合，每个集合称为一个连通分量。
2. 每个元素都被分配到一个集合中，集合中的元素彼此相互关联。
3. 并查集支持以下两种主要操作：
    （1）查找（Find）：查找元素所属的集合，确定元素所在的连通分量。判断两个元素是否
    属于同集合。
    （2）合并（Union）：合并两个不同的集合，将它们的元素合并成一个集合。

**应用**：解决==连通性==问题，如以下场景：

**图的连通性**：在无向图中判断两个节点是否连通，可以使用并查集来管理图的连通分量。
**最小生成树**：在克鲁斯卡尔算法中，通过并查集来判断两个节点是否属于同一棵树，以避免形成环路。
**社交网络分析**：在社交网络中，可以使用并查集来判断两个人是否属于同一个社交圈子。
**连通性问题**：例如，判断网络中的计算机是否连通，或者判断无向图中是否存在环路等。



#### 15.Trie树

**定义：**Trie 树（Trie Tree），也称为字典树，是一种用于高效存储和检索字符串集合的树状数据结构。

**特点**：

1. 前缀匹配：Trie 树以根节点表示空字符串，每个节点表示一个字符，从根节点到叶子节点的路径表示一个完整的字符串。
2. 字符存储：Trie 树将每个字符存储在节点中，不同的字符串可以共享相同的前缀路径。这使得Trie 树非常适合存储大量具有公共前缀的字符串集合。
3. 高效查找：查找操作的时间复杂度为O(k)，其中k 是要查找的字符串的长度。

**应用**：
单词搜索、IP 地址查找、前缀匹配、基因组序列分析



#### 16.判断链表是否有环（非常重要！）

判断一个链表是否有环是一个经典的问题，通常使用快慢指针算法（Floyd 算法）来解决。该算法的基本思想是，使用两个指针遍历链表，一个指针（慢指针）每次向前移动一步，另一个指针（快指针）每次向前移动两步。如果链表中有环，那么快指针最终会追上慢指针，否则快指针会先到达链表的末尾（null）。



### （三）计算机网络

#### 1.OSI七层模型

- **应用层**：为应用软件提供网络服务，如HTTP、FTP
- **表示层**：确保一个系统的应用层所表示的信息可以被另一个系统的应用层读取
- **会话层**：建立、管理和终止会话
- **传输层**：定义了一些传输数据的协议和端口号，如TCP和UDP
- **网络层**：进行逻辑地址寻址，实现不同网络之间的路径选择，如IP协议
- **数据链路层**：传输有地址的帧以及错误检测功能
- **物理层**：传输原始比特流



#### 2.TCP/IP模型

- **应用层**：对应于OSI参考模型的应用层、表示层和会话层
- **传输层**：对应于OSI模型的传输层
- **互联网层**：对应于OSI模型的网络层
- **网络接口层**：对应于OSI模型的数据链路层和物理层



#### 3.网络设备

- **路由器**：连接不同网络，使用IP地址进行数据包的路由选择
- **交换机**：连接同一网络内的不同设备，使用MAC地址进行数据帧的转发
- **调制解调器**：实现数字信号和模拟信号之间的转换



#### 4.协议

- **TCP**：提供可靠的、有序的、基于字节流的通信
- **UDP**：提供一种简单、不可靠的、无连接的通信服务
- **IP**：负责将数据包从源主机路由到目的主机
- **ICMP**：用于在IP主机、路由器之间传递控制消息



#### 5.IP地址

- **IPv4**：32位地址，提供有限的地址数量
- **IPv6**：128位地址，大幅扩展了地址空间



#### 6.网络空间

- **防火**墙：控制进出网络的数据流，防止未授权访问
- **VPN**：允许在公共网络中建立加密的、安全的通信隧道
- **加密**：保护数据传输过程中的隐私和完整性



#### 7.网络应用

- **DNS**：将域名解析为IP地址
- **DHCP**：自动分配IP地址给网络中的设备
- **NAT**：允许多个设备共享一个或一组公网IP地址



#### 8.TCP和UDP的异同点

相同：
1. 都是传输层协议，用于在不同主机之间的应用程序之间传输数据。
2. 都使用端口号来标识不同的应用程序，以便接收方将数据包传递给正确的应用程序。

不同：

1. TCP 是面向连接的协议，UDP 是无连接的协议。TCP 在传输数据前需要建立连接，而UDP
    直接发送数据包。
2. TCP 提供可靠的数据传输服务，它使用确认和重传机制来确保数据的正确性和完整性。
    而UDP 不提供可靠的数据传输服务，它仅仅是将数据包尽可能快地传递给接收方，不保证
    数据的正确性和完整性。
3. TCP 具有拥塞控制机制，可以调整发送速率以避免网络拥塞。而UDP 没有拥塞控制机制，
    可能会引起网络拥塞。
4. TCP 数据包的首部较长（至少20 个字节），UDP 数据包的首部较短（只有8 个字节）。
5. TCP 通常用于传输需要可靠性和有序性的数据，如文件传输和电子邮件等。而UDP 通常
    用于传输实时性要求高、可靠性要求不高的数据，如音频和视频等。
6. TCP 通信是点对点的，即一对一的通信。而UDP 通信可以是一对一、一对多或多对多的
    通信。



### （四）计组

#### 1.冯诺依曼机的体系结构

**特点**：计算机的指令和数据都存储在同一个存储器中，以二进制形式表示，并且可以在存储器中进行操作和传输。

**组成**：

- 存储器：存储器是计算机中用于存放程序和数据的设备。冯诺依曼机的存储器被划分为多个连续的存储单元，每个存储单元都有唯一的地址。指令和数据都存储在存储器中，可以通过地址来访问。
- 运算器：运算器是计算机中用于执行算术和逻辑运算的设备。它包括算术逻辑单元（ALU）、累加寄存器、状态寄存器等。运算器可以读取存储器中的数据，并对其进行运算和处理，然后将结果存回存储器中。
- 控制器：控制器是计算机中用于控制指令执行顺序和数据传输的设备。它包括指令寄存器、程序计数器、指令译码器等。控制器可以从存储器中读取指令，并根据指令的要求执行相应的操作。
- 输入输出设备：输入输出设备用于计算机与外部世界进行交互。例如，键盘、鼠标、显示器、打印机等。
- 总线：总线是计算机中用于数据传输的设备。它包括地址总线、数据总线、控制总线等。总线负责在各个设备之间传输数据和控制信息，实现计算机的各项功能。



#### 2.衡量计算机性能指标

1、**吞吐量**：表征一台计算机在某一时间间隔内能够处理的信息量，单位是字节/秒。
2、**响应时间**：表征从输入有效到系统产生响应之间的时间度量，用时间单位来度量，例如微秒（10-6S）、纳秒（10-9S）。
3、**利用率**：表示在给定的时间间隔内，系统被实际使用的时间所占的比率，一般用百分比表示。
4、**处理机字长**：指处理机运算器中一次能够完成二进制数运算的位数。当前处理机的字长有8 位、16 位、32 位、64 位。字长越长，表示计算的精度越高。
5、**总线宽度**：一般指CPU 中运算器与存储器之间进行互连的内部总线二进制位数。
6、**存储器容量**：存储器中所有存储单元的总数目，通常用KB、MB、GB、TB 来表示。其中K=210，M=220，G=230，T=240， B=8 位（1 个字节）。
7、**存储器带宽**：存储器的速度指标，单位时间内从存储器读出的二进制数信息量，一般用字节数/秒表示。
8、**主频**/**时钟周期**：CPU 的工作节拍受主时钟控制，主时钟不断产生固定频率的时钟，主时钟的频率（f）叫CPU 的主频。度量单位是MHz、GHz。主频的倒数称为CPU 时钟周期（T），即T=1/f，度量单位是微秒、纳秒。
9、**CPU 执行时间**：表示CPU 执行一段程序所占用的CPU 时间，可用下式计算： 

CPU执行时间＝ CPU 时钟周期数× CPU 时钟周期长



#### 3.原码、反码、补码

**机器数**：一个数在计算机中的二进制表示形式, 叫做这个数的机器数。机器数是带符号的，在计算机用一个数的最高位存放符号, 正数为0, 负数为1.
**原码**：原码是最基础的符号表示方法，用最高位表示符号位，0 表示正数，1 表示负数，其余位表示数值。例如，+7 用原码表示为0000111，-7 用原码表示为1000111。原码的优点是简单易懂，但存在加减法时需要进行符号位的特殊处理，且存在两个0（0000000 和
10000000），不利于数值的表示。
**反码**：反码的表示方式是在原码的基础上，正数的反码与原码相同，负数的反码是在原码的基础上，除符号位外，其余位取反。例如，+7 用反码表示为0000111，-7 用反码表示为1111000。反码的优点是加减法不需要特殊处理符号位，但存在几个问题，如仍存在两个0，以及对于0 和-0，反码表示是相同的，不利于计算机的实际应用。
**补码**：补码是现代计算机中广泛采用的符号表示方式。与反码相同，正数的补码与原码相同，负数的补码是在原码的基础上，除符号位外，其余位取反后加1。例如，+7 用补码表示为0000111，-7 用补码表示为1111001。补码的优点是几乎消除了其他两种编码的不足，
加减法不需要特殊处理符号位，仅需按照二进制加法即可，且仅存在一个0，-0 不存在，便于计算机的实际应用。

在计算机中，通常采用补码来表示有符号数，比如在CPU 的寄存器中进行加减运算时，常常采用补码运算。



#### 4.奇偶校验、汉明码校验，循环冗余校验

奇偶校验、汉明码校验和循环冗余校验都是数据传输中常用的错误检测技术。
**奇偶校验**：奇偶校验是一种基本的校验方法，它利用二进制数据中1 的个数的奇偶性来检测错误。例如，假设要发送一个8 位的二进制数据01001101，使用奇偶校验的方法，则可以在最高位添加一个附加位，使得整个数据中1 的个数为偶数，最终发送的数据为001001101。接收端也可以对接收到的数据进行奇偶校验，如果接收到的数据在某一位上的值与附加位不同，
则说明发生了错误。
**汉明码校验**：汉明码校验是一种更为强大的校验方法，可以检测并纠正多达两个比特的错误。它的原理是在数据中添加冗余的校验位，使得校验位可以检测到数据中的错误，并且通过一定的纠错算法可以修复这些错误。汉明码校验的实现方法包括系统化重复、垂直奇偶校验和Hamming 码等多种技术。
**循环冗余校验**：循环冗余校验是一种基于除法的校验方法，它通过将待传输的数据看做一个多项式，然后将该多项式除以一个特定的生成多项式来生成一个余数，将余数添加到待传输的数据中作为校验码。接收端也将接收到的数据看做一个多项式，然后将该多项式除以同样的生成多项式来生成余数，如果余数为0，则说明数据传输正确，否则说明数据传输发生了错误。循环冗余校验常用的生成多项式包括CRC-8、CRC-16、CRC-32 等。



#### 5.存储器的分类（RAM、DAM 的区别）

RAM 和DAM 是两种不同的存储器类型，具有以下区别：

1. RAM (Random Access Memory)是随机存取存储器，而DAM (Direct Access Memory)是直接访问
   存储器。
2. RAM 存储器通常用于计算机内存，而DAM 通常用于磁盘、磁带、光盘等存储设备。
3. RAM 存储器可以随机读写任意地址的数据，而DAM 存储器需要按照一定的顺序来读取或写入数据。
4. RAM 存储器访问速度比DAM 存储器快得多，但RAM 的容量通常较小，而DAM 的容量可以很大。
5. RAM 存储器是易失性存储器，断电后数据将丢失，而DAM 存储器是非易失性存储器，数据将持久保存。

根据存取方式的不同，可以将存储器分为随机存取存储器（Random Access Memory，RAM）和只读存储器（Read Only Memory，ROM）。

- 随机存取存储器（RAM）：RAM 是一种易失性存储器，读写速度快，数据存储在其中是暂时的。计算机在工作时需要用到的数据和程序都必须存放在RAM 中。内存条、内存芯片都是RAM 的例子。
- 只读存储器（ROM）：ROM 是一种非易失性存储器，数据被写入后不能进行修改和删除。ROM 用于存放启动程序、BIOS 等重要数据和程序，以保证计算机能够正常工作。



#### 6.段页式虚拟内存

**定义**：段页式虚拟内存是一种结合了==段式==存储管理和==页式==存储管理的虚拟内存管理方式，它可以克服两种存储管理方式的缺点，提高内存使用的效率和灵活性。
**过程**：在段页式虚拟内存中，一个进程的逻辑地址空间被分成若干个逻辑段，每个逻辑段再被分成若干个逻辑页，这些逻辑页再被映射到物理页框中。这样，每个逻辑段都有自己的段表，用于将逻辑地址转换为物理地址，每个逻辑页也有自己的页表，用于将逻辑页号转换为物理页框号。
**优点**：

- 灵活性高：可以将进程的逻辑地址空间按照段的方式进行管理，每个逻辑段的大小可以根据实际需要进行调整。
- 内存利用率高：可以将每个逻辑页映射到不同的物理页框中，从而最大限度地利用物理内存。
- 地址空间保护：每个进程的逻辑地址空间都是独立的，相互之间不能互相访问，从而保护了每个进程的地址空间。

**缺点**：

- 管理复杂：需要维护逻辑段表和页表，增加了内存管理的复杂性。
- 访问效率低：在进行地址转换时需要先进行段表的查找，再进行页表的查找，增加了访问内存的时间。
- 存储空间浪费：由于逻辑段的大小不同，每个逻辑段的末尾可能会出现一些无法使用的空间，从而浪费了存储空间。



#### 7.cpu 一个指令周期的流程

1. 取指令（Instruction Fetch，IF）：从指令寄存器中取出下一条要执行的指令。
2. 指令译码（Instruction Decode，ID）：将取出的指令进行译码，确定操作类型、寻址方式和操作数等信息。
3. 寄存器操作（Register Operation，RO）：根据指令中的寄存器操作码，对寄存器进行读写。
4. 计算（Execute，EX）：执行算术逻辑运算、数据传输等操作。
5. 存储访问（Memory Access，MA）：进行读写内存操作，根据地址从内存中取出数据或将数据写入内存。
6. 结果写回（Write Back，WB）：将计算结果写回寄存器。

以上6 个阶段称为经典的五级流水线，其中第3、4、5 个阶段可以并行执行，提高了CPU的运行效率。



#### 8.总线通讯的四种方式

1. 控制总线方式：即主机通过控制总线来控制从机进行数据传输。在该方式中，主机具有总线的控制权，通过控制总线来与从机进行通信，可以控制总线上的数据传输。
2. 存储器映射方式：在存储器映射方式下，整个计算机系统被看成一个内存空间。主机和从机都可以读取和写入这个内存空间，通过内存地址进行通信。该方式中主机和从机之间的通讯是通过内存地址空间实现的。
3. 端口映射方式：在端口映射方式下，计算机系统被看成是一组I/O 设备的集合。主机通过读取或写入端口号来进行通信，这些端口号代表特定的设备或设备接口。在该方式下，主机和从机之间的通讯是通过I/O 端口实现的。
4. 直接内存访问方式：在直接内存访问方式下，主机将数据传输任务交给DMA 控制器，DMA 控制器直接与存储器进行通讯，实现数据传输。在该方式下，主机和从机之间的通讯是通过DMA 控制器实现的。由于该方式绕开了主机CPU，可以提高数据传输速度，因此在高速数据传输场合中应用广泛。



#### 9.CPU 和GPU 的区别和作用

CPU（中央处理器）和GPU（图形处理器）是计算机系统中两种不同类型的处理器，它们在作用和特点上存在一些区别。
**作用**：

- CPU：CPU 是计算机系统的核心处理器，负责执行大部分的计算任务和控制计算机的各个组件。CPU 处理各种通用计算任务，如操作系统的运行、应用程序的执行、算术和逻辑运算等。
- GPU：GPU 最初设计用于处理图形和图像相关的计算任务，如游戏渲染、图形设计、视频处理等。与CPU 相比，GPU 具有大量的处理单元（称为流处理器或CUDA 核心），并行处理能力强，适合处理大规模数据并执行高度并行的计算任务。

**区别**：

1. **架构**：CPU 的设计目标是处理各种通用计算任务，它具有较少的处理核心，但每个核心都较为强大。GPU 的设计目标是高度并行的计算，它通常具有大量的小型处理核心，但每个核心相对较弱，主要用于执行简单的浮点运算。
2. **计算方式**：CPU 更适合处理顺序和串行的任务，能够处理复杂的控制流程和分支逻辑。GPU 则擅长并行计算，能够同时执行大量的相似计算任务。
3. **内存架构**：CPU 和GPU 的内存架构也有所区别。CPU 通常有几级缓存和内存控制器，可以直接访问系统内存。GPU 具有自己的显存（高速显存），用于存储图形和计算所需的数据，GPU 的核心可以共享显存，以实现更高效的数据共享和并行计算。



#### 10.多GPU 计算

多GPU 计算的优势在于可以显著加快计算速度并提高计算效率。通过将计算任务分布到多个GPU 上并行执行，可以同时处理更多的数据或模型，从而减少整体的计算时间。多GPU 计算还能够充分利用每个GPU 的计算能力，提高系统的吞吐量和并行性。



#### 11.Cache

**定义**：Cache（缓存）是计算机系统中的一种高速存储器，用于临时存储经常访问的数据，以
提高数据访问的速度和效率。它位于主存（内存）和CPU 之间，作为中间层，用于加速数
据的读取和写入操作。

**指标**：

1. 命中率（Hit Rate）：它表示在访问缓存时，能够从缓存中获取到所需数据的比例。命中率越高，性能越好。
2. 缓存命中时间（Cache Hit Time）：缓存命中时间是指当缓存中存在所需数据时，从缓存中获取数据所需的时间。较低的缓存命中时间意味着更高的性能。
3. 缓存失效时间（Cache Miss Time）：缓存失效时间是指当缓存中不存在所需数据时，从主存或其他存储层获取数据并将其加载到缓存中所需的时间。较低的缓存失效时间可以减少缓存未命中时的延迟。
4. 平均访问时间（Average Access Time）：它表示对于整个系统的访问请求，平均需要花费的时间。较低的平均访问时间意味着更好的性能。
5. 缓存容量（Cache Capacity）：缓存容量指的是缓存能够存储的数据量大小。较大的缓存容量可以提高缓存命中率，减少缓存未命中的频率。
6. 缓存替换策略（Cache Replacement Policy）：缓存替换策略用于确定在缓存空间不足时，哪些数据将被淘汰出缓存。常见的缓存替换策略包括最近最少使用（Least Recently Used,LRU）、先进先出（First In, First Out, FIFO）等。选择合适的缓存替换策略可以影响缓存性能和命中率。



### （五）编程语言(我学的是c,这一块全是c/c++)

#### 1.指针和引用的区别

- **定义和使用不同**：指针是一个==变量==，存储着另一个变量的地址，使用时需要使用解地址符*和取地址符&;引用则是另一个变量的==别名==，使用时不需要特殊符号，直接使用引用即可
- **可空性不同**：指针可以为空，即指向nullptr或NULL，而引用必须初始化为一个已经存在的变量，因此不存在空引用的概念
- **赋值和绑定行为不同**：指针可以在不同的时刻指向不同的变量，也可以为空或无效，因此可以通过赋值来改变指针所指向的对象；而引用一旦绑定到一个变量上，就无法改变所指向的对象，因此赋值操作会改变所指向变量的值，而不是引用本身
- **指向数组和函数的能力不同**：指针可以通过数组名和函数名来获得数组和函数的地址，从而可以处理数组和函数。而引用无法直接指向数组和函数，必须通过指针来实现。



#### 2.深拷贝和浅拷贝

**深拷贝**：将整个对象复制一个新的，并且新对象和原对象在内存中的地址是不同的。因此，修改新对象的属性，不会影响原对象。

**浅拷贝**：只复制其==指针地址==，新对象和原来的对象指向相同的内存地址。因此，如果修改新对象的某些属性，原对象的对应属性也会被修改。



#### 3.==程序的编译过程==

- **预处理**：编译器会根据源代码中的预编译指令，如#include和#define等，将多个源文件合并成单一的源文件，同时进行宏替换等操作
- **编译**：在这个过程中，编译器会进行词法分析、语法分析、语义分析等操作，检查代码的合法性和语义正确性，并生成对应的汇编代码
- **汇编**：这个过程中，汇编器会将汇编代码转换为机器指令，并生成目标文件的可执行文件格式
- **链接**：链接器将多个目标文件和库文件合并为一个可执行文件



#### 4.多态

c++实现多态有两种方式：

- **虚函数**（动态多态）：通过在基类中定义虚函数，在派生类中覆盖这些函数，实现动态绑定，即在运行时根据对象的类型来决定调用哪个函数
- **模版**（静态多态）：通过c++中的模板机制，实现静态多态，在编译时根据函数参数类型来决定调用哪个函数



#### 5.Java、c++、c的区别

1. Java 程序的运行依赖于Java 虚拟机（JVM），C++是一种面向对象的编程语言，C 是一种面向过程的编程语言
2. Java 不能在类之外的地方定义全局变量，只能在一个类中定义静态变量来实现一个全局变量。C/C++可以直接在类之外定义全局变量。
3. Java 不支持C/C++的goto 语句，而是通过try、catch 来代替C/C++的goto 来处理异常时控制。
4. C/C++可以通过指针进行内存地址操作。Java 对指针进行完全的控制，不能在程序中进行任何指针操作
5. C/C++中可以通过某些函数进行内存的分配和释放。在Java 中通过new 运算符进行内存随着程序运行动态分配，且Java 能够进行自动管理和自动垃圾回收，防止内存资源产生的操作错误和浪费。
6. C/C++对于不同的平台，数据类型的长度不同，代码不可移植。Java 对数据类型总是分配固定长度位数，保证平台无关性。
7. C++可以通过指针进行任意类型的转换，Java 在进行类型转换时会进行类型相容性检查，防止不安全的转换。
8. C/C++中用头文件声明类的原型及全局变量、库函数。Java 不支持头文件，导入其他类要使用import 语句。
9. C++中的结构体和联合体所有成员都是共有的，这有一定的安全问题。Java 中没有结构体和联合体，一切内容都封装在类中。
10. C++支持宏定义，Java 不支持宏定义。

**背诵**

1. The running of Java programs relies on the Java Virtual Machine (JVM), where C++is an object-oriented programming language and C is a procedural programming language

2. Java cannot define global variables outside of a class, only static variables can be defined within a class to implement a global variable. C/C++can directly define global variables outside of a class.
3. Java does not support C/C++goto statements, but instead uses try and catch instead of C/C++goto to handle exception time control.
4. C/C++can perform memory address operations through pointers. Java has complete control over pointers and cannot perform any pointer operations in the program
5. In C/C++, memory allocation and release can be performed through certain functions. In Java, the new operator is used to dynamically allocate memory as the program runs, and Java can perform automatic management and garbage collection to prevent operational errors and waste of memory resources.
6. C/C++has different data type lengths for different platforms, and the code is not portable. Java always assigns fixed length bits to data types to ensure platform independence.
7. C++can perform any type conversion through pointers, and Java performs type compatibility checks during type conversion to prevent unsafe conversions.
8. In C/C++, declare class prototypes, global variables, and library functions using header files. Java does not support header files, importing other classes requires the use of an import statement.
9. In C++, all members of structures and unions are common, which poses certain security concerns. There are no structures or unions in Java, everything is encapsulated in classes.
10. C++supports macro definition, while Java does not support macro definition.



## 三、人工智能

### （一）机器学习

#### 模型评估

##### 1.AUC-ROC曲线评估分类器性能

AUC表示ROC曲线下的面积，用于评估分类模型的二分类性能。ROC曲线是TPR和FPR的图形表示，其中TPR是召回率的另一个名称。AUC值越高，表示模型性能越好，理想情况下AUC值为1

##### 2.精确度与召回率的权衡

精确度Pr是正确预测为正类别样本占所有预测为正类样本的比例，而召回率Re是正确预测为正类别的样本占所有实际为正类别样本的比例。精确度关注的是减少误报，而召回率关注的是减少漏报。在实际应用中，根据问题的性质，可能会更重视精确度或召回率



#### 集成方法

##### 1.随机森林算法的实现

随机森林是一种集成学习算法，通过构建多个决策树并进行投票或平均来提高模型的性能。在构建每棵决策树时，随机森林会从训练集中随机选择样本（带替换），并从特征中随机选择一部分用于分裂决策



##### 2.Boosting和Bagging的区别

Bagging（Bootstrap Aggregating）是一种简单的集成方法，它通过在原始数据集上进行多次有放回的抽样来训练多个模型，然后平均或投票这些模型的预测结果。Boosting是一种顺序集成方法，它逐步训练模型，每一个新模型都尝试纠正前一个模型的错误。Boosting关注减少偏差，而Bagging关注减少方差



#### 深度学习理论

##### 1.梯度消失和梯度爆炸问题

- 梯度消失是指在深度神经网络中，由于连续乘积的反向传播，梯度值可能变得非常小，导致权重更新缓慢。

- 梯度爆炸则相反，梯度值可能变得非常大，导致权重更新过于剧烈。解决这些问题的方法包括使用ReLU激活函数、梯度剪切、使用批量归一化或改变网络结构



##### 2.LSTM网络中门控机制的作用

LSTM网络中门控机制包括输入门和遗忘门，用于控制信息的流入和流出。输入门决定新信息的存储量，遗忘门决定旧信息的遗忘量。输出门则用于决定输出哪些信息。这种机制使得LSTM能够学习长期依赖关系



##### 3.监督学习与无监督学习

**监督学习**：这是一种机器学习类型，其中模型从带有标签的训练数据中学习，以便能够预测或决定未见过的数据的标签。例如，在图像识别中，模型学习将图像与正确的对象类型相匹配

**无监督学习**：在这种类型的机器学习中，模型处理的数据没有标签。模型试图通过自己发现数据中的结构和模型来理解数据。常见的无监督学习任务包括聚类和关联规则学习



##### 4.特征工程

特征工程是机器学习中的一个关键步骤，涉及从原始数据中选择、构建和转换特征，以提高模型的性能。这个过程可能包括特征选择（选择最相关的特征）、特征提取（从原始数据中创建新特征）和特征构造（将多个特征组合成更有意义的特征）



##### 5.过拟合与欠拟合

**过拟合**：当一个模型在训练数据上表现得非常好，但在新的、未见过的数据上表现不佳时，就发生了欠拟合。这通常表明模型过于复杂，学习了训练数据中的噪声和细节，而不是潜在的模式

**欠拟合**：当模型在训练数据上表现不足，无法捕捉数据的基本趋势时，就发生了欠拟合。这可能是因为模型太简单，没有足够的能力来学习数据中的复杂性



##### 6.交叉验证

交叉验证是一种统计方法，用于评估并提高模型的预测性能。它通过将数据集分割成多个小的部分，然后使用其中的一部分作为测试集，其余部分作为训练集，来重复进行模型训练和评估的过程。最常见的交叉验证技术是K折交叉验证，其中k通常取值为5或10



##### 7.决策树

决策树时一种直观的分类和回归工具，它通过一系列的问题将数据分割成越来越小的集合，直到达到基本的决策规则。每个问题都对应于数据中的一个特征，而每个分割的集合对应于一个节点或叶节点。决策树通过树状结构来表示决策过程，能够处理数值和类别数据，并且模型结果易于解释



##### 8.随机森林

随机森林是一种集成学习方法，它构建多个决策树并将它们的预测结果结合起来，以提高模型的准确性和鲁棒性。在随机森林中，每棵树在训练时使用数据集的一个随机子集，并且每个分裂时考虑随机选择的特征子集。这种方法减少了模型的方差，提高了模型的泛化能力，并且通常能够提供比单棵决策树更好的性能



##### 9.正则化

- 模型正则化是一种防止模型过拟合的技术，通过在模型的损失函数中添加一个额外的惩罚项来实现
- L2正则化（欧几里得范数）公式为：$L_{total}(\theta)=L(\theta)+\lambda \sum^{n}_{i=1}\theta^2_i$​
- L1正则化（曼哈顿距离或L1范数）公式为：$L_{total}(\theta)=L(\theta)+\lambda\sum^{n}_{i=1}|\theta_i|$
- 在这两个公式中,$L(\theta)$是原始的损失函数，$\theta_i$是模型参数，$\lambda$是正则化系数，$n$是参数的数量





#### 优化算法

##### 1.Adam优化器

Adam优化器结合了动量Momentum和RMSprop两种优化算法的优点。它使用不同的学习率自适应地更新每个参数，这使得它在实践中通常表现良好，尤其是在处理稀疏梯度时

##### 2.使用二阶导数信息优化模型

使用二阶导数信息（即Hessian矩阵）可以提供关于函数曲率的信息。牛顿法和拟牛顿法就是利用二阶导数信息来寻找最优点的优化算法。然而，由于计算和存储Hessian矩阵在大规模问题中通常不可行，因此在实践中常常使用近似方法，如L-BFGS



#### 特征工程

##### 1.主成分分析进行降维

PCA是一种统计方法，它通过正交变换将数据转化到新的坐标系中，使得新坐标系的第一主成分具有最大的方差（数据的最大变异性），第二主成分具有第二大的方差，依此类推。通过选择前几个主成分，可以减少数据的维度，同时保留大部分变异性

##### 2.t-SNE算法的工作原理

t-SNE是一种非线性降维技术，用于将高维数据映射到低维空间（通常是二维或三维），以便可视化。t-SNE通过优化一个目标函数来保持高维空间中相似的数据点在低维空间中也相似，同时差异较大的数据点在低维空间中差异也大



### （二）深度学习

#### 生成对抗网络（GANs）

##### 1.GANs的工作原理

GANs由生成器(generator)和判别器(discriminator)组成，生成器的目标是生成尽可能真实的数据，而辨别器的目标是区分真实数据和生成器生成的假数据。这两个网络在训练过程中相互竞争，生成器不断学习如何生成更真实的数据，而判别器不断学习如何更好地区分真假数据

##### 2.解决GAN训练中的模式崩溃问题

模式崩溃是指生成器开始生成非常相似或重复的样本，而不是多样化的输出。这个问题的解决方法包括使用小型的判别器、修改损失函数、引入正则项、使用多个生成器或判别器等



#### 深度学习中的正则化技术

##### 1.权重衰减

权重衰减是一种正则化技术，通过在损失函数中添加一个与权重大小成比例的惩罚项来防止模型过拟合。这鼓励模型学习较小的权重，从而减少过拟合的风险

##### 2.标签平滑

标签平滑是一种用于深度神经网络的正则化技术，它将硬标签（one-hot编码）替换为软标签，这有助于模型学习更加泛化的特征表示，减少对训练数据的过度拟合



#### 注意力机制

##### 1.注意力机制在序列模型中的作用

注意力机制允许模型在序列的不同部分之间建立联系，使模型能够集中关注对当前任务最重要的信息。在序列到序列模型中，注意力机制可以显著提高翻译、文本摘要等任务的性能

##### 2.实现Transformer模型

Transformer模型是一种基于注意力机制的模型，它完全摒弃了循环神经网络结构，使用自注意力机制来捕捉序列内部的长距离依赖关系。它由编码器和解码器组成，每个部分都包含多个相同的层，每层都包含自注意力和前馈神经网络



#### 深度学习中的自监督学习

##### 1.自监督学习的概念

自监督学习是一种无监督学习方法，它使用数据作为监督信号。模型被训练来预测其输入的某些方面，例如预测视频的下一帧或重构输入数据的噪声版本。这种方法可以用于预训练深度学习模型，然后再在监督任务上进行微调

##### 2.使用对比学习来训练模型

对比学习是一种自监督学习方法，它通过比较不同的数据点来训练模型。常见的方法是将正样本（相似的数据点）和负样本（不相似的数据点）配对，然后训练模型以拉进正样本的距离，推开负样本的距离



#### 深度学习中的多任务学习

##### 1.多任务学习的概念

多任务学习是一种机器学习范式，其中模型被训练来同时执行多个相关人物。这可以通过共享网络的底层表现来实现，从而提高模型在每个任务上的性能

##### 2.设计一个多任务学习的网络架构

多任务学习的网络架构通常包含一个共享的底层，用于学习所有任务的通用特征，以及每个任务特有的顶层。共享底层可以是一个卷积神经网络、循环神经网络或Transformer等，而顶层则根据每个任务的需要进行设计



## 四、面试题目

### （一）东南大学

#### Palm面试

- PPT自我介绍
- 项目提问
- 数学能力
- 如何评价自己的编程能力
- 未来想要从事的研究方向是什么
- 读研规划是什么
- 目前报了哪些学校，有哪些offer？

#### 案例1（中九985 rk8.7% 2023届cv）

1.5分钟PPT自我介绍

2.英语问题：

- 计算机视觉与图像处理的区别
- 你认为它们是相关的还是不同的

3.项目问题

- 这个项目的创新点在哪
- 为什么要这么做这个项目
- 一致化正则化过程是什么
- 有没有考虑过除了背景图像以外的额外信息
- 预测结果中什么类的样本预测结果不好
- 背景图像可能在某些场景下不好获取，那么在没有背景图像下是否一样有良好的表现结果呢

#### 案例2（中2 rk5.4% 2023届cv）

1.5分钟PPT自我介绍

2.英语问题：

- 你的项目对比了哪些方法，分别有什么优缺点？
- 你的项目的难点是什么？

3.项目问题

- 你的项目解决了什么问题
- 为什么选择图卷积神经网络
- 图卷积神经网络的原理是什么
- GCN和传统的卷积神经网络有什么不同
- 在你的项目中，你是怎么处理图数据的
- 你的模型效果怎么样？你是怎么评估的

4.你对某个研究方向有什么见解



#### 案例3（末9 rk9.3% 2023届大数据）

1.5分钟PPT自我介绍

2.英语问题：

-  请介绍一下你的项目
- 你对这个项目的贡献是什么？

3.项目问题

- 你的特征筛选是怎么做的？
- 为什么选择XGboost算法？
- XGBoost的原理是什么
- XGBoost和随机森林有什么区别
- 在你的项目中，XGBoost有没有考虑过拟合的问题？
- 跟其他模型对比，你的模型有什么不足？
- 你有没有对XGBoost做改进？还是只是简单的调包?
- 在训练过程中遇到的困难是怎么解决的？



### （二）浙软

#### 考核方式

机试15%+面试85%,机试成绩一般决定面试成绩

机试为ioi赛制，时间为3小时



#### 机试题目

1.合并区间后，求区间最后一个数与第一个数的距离

2.合并区间后，用两根等长的整数直线对区间进行覆盖，求两根直线总共的最短长度

3.合并区间后，用k根直线（不要求等长）对区间进行覆盖，求所有直线的最短长度

4.合并区间后，用k根直线(要求等长)对区间进行覆盖，求直线最短长度



#### 面试一

1.1~2分钟英文自我介绍

2.6~8分钟个人称述

3.NLP的定义是什么？机器语言与自然语言的区别是什么？

4.信息熵越大，编码数据的长度越大还是越小？

5.对论文内容深入提问



#### 面试二

1.什么是olap,olpt?

2.请简单介绍一下列式存储模型以及行式存储模型？

3.请详细介绍一下数据库的设计步骤？

4.设计师一般考虑什么因素设计索引？

5.数据库索引的底层实现数据结构是什么？

6.科研竞赛项目有什么创新点，遇到了哪些困难，如何解决？



### （三）复旦

#### 大数据学硕

1.英文自我介绍

2.最喜欢的课程和原因

3.线性回归和逻辑回归阐述

4.线性回归和逻辑回归有什么区别和联系

5.什么是随机梯度下降

6.批量梯度下降是什么？是否会用到随机梯度下降

7.megatron做了什么工作

8.什么是data parallel、model parallel和pipeline parallel

9.all-reduce这个通信原语可以被分为哪几个通信原语



#### 电子信息直博

1.数据传输最快一秒可以传多少位

2.机试算法的思路和优化

3.项目经历



#### 网安

1.使用dfs时候的栈溢出是什么？

2.B树和B+树的区别？

3.哈希是什么？哈希的复杂度是多少？哈希的优缺点？给出三种解决哈希冲突的办法

4.项目中的难点以及如何解决
